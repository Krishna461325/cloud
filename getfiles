import os
import re
import time
import concurrent.futures


class FileGetter:
    def __init__(self):
        self.path = None
        self.age = None
        self.patterns = None
        self.recursive = None
        self.min_depth = None
        self.max_depth = None
        self.num_workers = None

    def get_files(self, path=None, age=None, patterns=None, recursive=False, min_depth=None, max_depth=None, num_workers=None):
        if path is not None:
            self.path = path
        if age is not None:
            self.age = age
        if patterns is not None:
            self.patterns = patterns
        if recursive is not None:
            self.recursive = recursive
        if min_depth is not None:
            self.min_depth = min_depth
        if max_depth is not None:
            self.max_depth = max_depth
        if num_workers is not None:
            self.num_workers = num_workers

        if self.path is None:
            raise ValueError("path is not set")
        if self.age is None:
            raise ValueError("age is not set")
        if self.patterns is None:
            raise ValueError("patterns is not set")
        if not self.recursive and (self.min_depth is None or self.max_depth is None):
            self.min_depth = 1
            self.max_depth = 1

        if self.num_workers is None:
            return self._search_files(self.path)
        else:
            return self._search_files_threaded(self.path)

    def _search_files(self, path):
        matching_files = []
        for entry in os.scandir(path):
            if entry.is_file(follow_symlinks=False):
                if any(re.match(pattern, entry.name) for pattern in self.patterns):
                    file_age = time.time() - entry.stat(follow_symlinks=False).st_mtime
                    if file_age > self.age * 24 * 3600:
                        matching_files.append(entry.path)
            elif self.recursive and entry.is_dir(follow_symlinks=False):
                if self.min_depth is not None and self.max_depth is not None:
                    depth = entry.path[len(path.rstrip(os.path.sep))+1:].count(os.path.sep) + 1
                    if depth < self.min_depth or depth > self.max_depth:
                        continue
                matching_files += self._search_files(entry.path)
        return matching_files

    def _search_files_threaded(self, path):
        matching_files = []
        with concurrent.futures.ThreadPoolExecutor(max_workers=self.num_workers) as executor:
            future_to_path = {executor.submit(self._search_files, entry.path): entry for entry in os.scandir(path) if entry.is_dir(follow_symlinks=False)}
            for future in concurrent.futures.as_completed(future_to_path):
                matching_files += future.result()
        matching_files += self._search_files(path)
        return matching_files


#how to use

file_getter = FileGetter()
matching_files = file_getter.get_files(path='/path/to/directory', age=30, patterns=['.*\.txt', '.*\.csv'], recursive=True, min_depth=1, max_depth=2, num_workers=4)
